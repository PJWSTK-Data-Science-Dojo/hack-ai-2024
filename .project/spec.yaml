specVersion: v2
specMinorVersion: 2
meta:
  name: deep-video
  image: project-deep-video
  description: Project for video analysis
  labels: []
  createdOn: "2024-09-15T18:00:00Z"
  defaultBranch: main
layout:
- path: dsc_hackai/
  type: code
  storage: git
- path: models/
  type: models
  storage: gitlfs
- path: data/
  type: data
  storage: gitlfs
- path: data/scratch/
  type: data
  storage: gitignore
environment:
  base:
    registry: docker.io
    image: pytorch/pytorch:2.3.1-cuda11.8-cudnn8-runtime
    build_timestamp: "20231102150513"
    name: PyTorch
    supported_architectures: []
    cuda_version: "11.8"
    description: A Pytorch 2.3.1 Base with CUDA 11.8
    entrypoint_script: ""
    labels:
    - cuda11.8
    - pytorch2.3
    apps: []
    programming_languages:
    - python3
    icon_url: ""
    image_version: 2.3.1
    os: linux
    os_distro: ubuntu
    os_distro_release: "22.04"
    schema_version: v2
    user_info:
      uid: ""
      gid: ""
      username: ""
    package_managers:
    - name: apt
      binary_path: /usr/bin/apt
      installed_packages:
      - curl
      - git
      - git-lfs
      - python3
      - gcc
      - python3-dev
      - python3-pip
      - vim
      - less
      - jq
      - ssh
    - name: pip
      binary_path: /usr/local/bin/pip
      installed_packages:
      - jupyterlab==4.0.7
    package_manager_environment:
      name: ""
      target: ""
execution:
  apps:
  - name: Visual Studio Code
    type: vs-code
    class: native
    start_command: ""
    health_check_command: '[ \$(ps aux | grep ".vscode-server" | grep -v grep | wc
      -l ) -gt 4 ] && [ \$(ps aux | grep "/.vscode-server/bin/.*/node .* net.createConnection"
      | grep -v grep | wc -l) -gt 0 ]'
    stop_command: ""
    user_msg: ""
    logfile_path: ""
    timeout_seconds: 120
    icon_url: ""
  - name: Chat Frontend
    type: custom
    class: webapp
    start_command: python -m streamlit run frontend/Home.py --server.port 8080
    health_check_command: exit 0
    stop_command: ps aux | grep streamlit | grep -v grep | awk '{print $2}' | xargs
      kill
    user_msg: ""
    logfile_path: ""
    timeout_seconds: 60
    icon_url: ""
    webapp_options:
      autolaunch: true
      port: "8080"
      proxy:
        trim_prefix: false
      url: http://localhost:8080/
  - name: WhisperX
    type: custom
    class: process
    start_command: /project/apps/whisperx.sh start
    health_check_command: /project/apps/whisperx.sh status
    stop_command: /project/apps/whisperx.sh stop
    user_msg: ""
    logfile_path: ""
    timeout_seconds: 60
    icon_url: milvus.io/favicon-32x32.png
  resources:
    gpu:
      requested: 1
    sharedMemoryMB: 4096
  secrets:
  - variable: HF_TOKEN
    description: Huggingface token
  mounts:
  - type: project
    target: /project/
    description: Project directory
    options: rw
  - type: host
    target: /var/host-run/
    description: Host's runtime files for Docker in Docker support.
    options: ""
  - type: host
    target: /home/workbench/.cache/nvidia-nims/
    description: A path where NIM containers can store and share their cache.
    options: ""
